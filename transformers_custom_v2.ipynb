{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cld0033/Tone_It_Down/blob/main/transformers_custom_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom fine-tuneable model for Tone it Down\n",
        "\n",
        "This is the python notebook used to generate a custom Transformers model for the Tone it Down app based on a Hugging Face dataset."
      ],
      "metadata": {
        "id": "MrVOUx5CrFnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install relevant packages:"
      ],
      "metadata": {
        "id": "amnkucWi9LjN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 480,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rXsPw_h9lAv",
        "outputId": "2cf2c466-c8c3-46bf-c514-4d6ad4f85c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec==2024.10.0\n",
            "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.9.0\n",
            "    Uninstalling fsspec-2024.9.0:\n",
            "      Successfully uninstalled fsspec-2024.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.1.0 requires fsspec[http]<=2024.9.0,>=2023.1.0, but you have fsspec 2024.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#install if not installed; hide output\n",
        "!pip install fsspec==2024.10.0 #gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
        "!pip install datasets -q\n",
        "!pip install transformers -q\n",
        "!pip install torch -q\n",
        "!pip install onnx onnxruntime -q\n",
        "!pip install optimum -q\n",
        "!pip install Cmake -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 481,
      "metadata": {
        "id": "-VjLYwIs9eFH"
      },
      "outputs": [],
      "source": [
        "#import relevant libraries\n",
        "import torch\n",
        "import datasets\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments, EncoderDecoderCache, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the T5 tokenizer and model"
      ],
      "metadata": {
        "id": "5yvR6QCt9RjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used bert-base-uncased model for classification. Since there were 67 unique labels in the dataset, loaded the model with num_labels=67"
      ],
      "metadata": {
        "id": "CN8fc8FtKHS9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 482,
      "metadata": {
        "id": "meMEXPkj98bO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493e6433-ccdf-464c-d87c-7e1430732d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#load a tokenizer and training model\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load the model with 67 labels\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=67)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and pre-process a dataset from Huggingface\n",
        "\n",
        "1. Cleaned the dataset by removing the idx column and splitting into a training and validation set\n",
        "2. Mapped each unique label to a unique integer, which is compatible with machine learning models (note - mapping is stored in label_mapping)\n",
        "3. Applied a preprocess function that should tokenize what's in the \"text\""
      ],
      "metadata": {
        "id": "oyGDCW5H9Z7l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 483,
      "metadata": {
        "id": "5GVp3yYQqnao"
      },
      "outputs": [],
      "source": [
        "#load a dataset\n",
        "dataset = datasets.load_dataset(\"uhoui/text-tone-classifier\")\n",
        "#https://huggingface.co/datasets/uhoui/text-tone-classifier/viewer/default/train?f%5Bidx%5D%5Bmin%5D=80&f%5Bidx%5D%5Bmax%5D=90 <-- I used this one bc of the dataset() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 484,
      "metadata": {
        "id": "FUOHod56x7mU"
      },
      "outputs": [],
      "source": [
        "#remove idx column\n",
        "dataset = dataset.remove_columns(\"idx\")\n",
        "\n",
        "#manually created splits\n",
        "num_samples = len(dataset['train'])\n",
        "train_indices, val_indices = train_test_split(range(num_samples), test_size=0.2, random_state=42)\n",
        "\n",
        "# Create train and validation datasets using select\n",
        "train_dataset = dataset['train'].select(train_indices)\n",
        "val_dataset = dataset['train'].select(val_indices)\n",
        "\n",
        "# Create a DatasetDict with separate splits\n",
        "split_dataset = datasets.DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 485,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWoEVuQHsjWo",
        "outputId": "829f2ddf-3852-4b6f-c703-b35be5c4a055",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split dataset: \n",
            " DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 392\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 99\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "#verify that split happened\n",
        "print(\"split dataset: \\n\", split_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify unique labels across both train and validation sets\n",
        "unique_labels_train = set(split_dataset['train']['label'])\n",
        "unique_labels_val = set(split_dataset['validation']['label'])\n",
        "\n",
        "print(f\"Unique labels in train set: {unique_labels_train}\")\n",
        "print(f\"Unique labels in validation set: {unique_labels_val}\")\n",
        "\n",
        "# Combine the labels from both sets to see the full range\n",
        "unique_labels_all = unique_labels_train.union(unique_labels_val)\n",
        "print(f\"Unique labels in the entire dataset: {unique_labels_all}\")\n",
        "print(len(unique_labels_all))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfoK1S9l1Lly",
        "outputId": "3dbeb066-03f6-493a-ae4c-a2981875dd86"
      },
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in train set: {'awe', 'adventure', 'joy', 'chill', 'bliss', 'nostalgia', 'comfort', 'compassion', 'concern', 'adrenaline', 'connection', 'Neutral', 'worry', 'pleasure', 'bittersweetness', 'parting', 'despair', 'positive', 'Serious', 'accomplishment', 'sorrow', 'disgust', 'courage', 'love', 'determination', 'peace', 'tension', 'longing', 'Negative', 'admiration', 'Positive', 'surprise', 'amusement', 'empathy', 'restlessness', 'relief', 'stress', 'anticipation', 'negative', 'depression', 'excitement', 'fear', 'tranquility', 'annoyance', 'inspiration', 'grief', 'pride', 'disappointment', 'pain', 'sadness', 'Sarcastic', 'gratitude', 'anxiety', 'happiness', 'neutral', 'anger', 'loneliness', 'reflection', 'contentment', 'curiosity'}\n",
            "Unique labels in validation set: {'awe', 'joy', 'nostalgia', 'comfort', 'concern', 'Neutral', 'worry', 'pleasure', 'Serious', 'positive', 'disgust', 'hope', 'appreciation', 'love', 'heat', 'Negative', 'Positive', 'surprise', 'empathy', 'relief', 'stress', 'anticipation', 'negative', 'fear', 'serenity', 'annoyance', 'pride', 'disappointment', 'rejection', 'sadness', 'Sarcastic', 'elation', 'happiness', 'neutral'}\n",
            "Unique labels in the entire dataset: {'adventure', 'joy', 'chill', 'bliss', 'nostalgia', 'comfort', 'concern', 'adrenaline', 'Neutral', 'worry', 'bittersweetness', 'parting', 'despair', 'Serious', 'accomplishment', 'disgust', 'love', 'determination', 'peace', 'tension', 'longing', 'admiration', 'heat', 'surprise', 'empathy', 'stress', 'anticipation', 'depression', 'excitement', 'tranquility', 'serenity', 'annoyance', 'pride', 'rejection', 'sadness', 'Sarcastic', 'loneliness', 'happiness', 'curiosity', 'awe', 'compassion', 'connection', 'pleasure', 'positive', 'sorrow', 'hope', 'courage', 'appreciation', 'Negative', 'Positive', 'amusement', 'restlessness', 'relief', 'negative', 'fear', 'inspiration', 'grief', 'disappointment', 'pain', 'gratitude', 'elation', 'anxiety', 'neutral', 'anger', 'reflection', 'contentment'}\n",
            "66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Initialize label_mapping as a defaultdict to avoid key errors\n",
        "label_mapping = defaultdict(lambda: None)  # Default value is None\n",
        "current_label_index = 0\n",
        "\n",
        "# Function to update the labels with integer mapping\n",
        "def update_label(examples):\n",
        "    global current_label_index\n",
        "\n",
        "    # Iterate through the labels and assign integer values\n",
        "    for i, label in enumerate(examples['label']):\n",
        "        if label not in label_mapping:\n",
        "            print(f\"Adding label: {label}\")\n",
        "            label_mapping[label] = current_label_index\n",
        "            current_label_index += 1  # Increment index for the next new label\n",
        "        examples['label'][i] = label_mapping[label]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# Apply label update to both the train and validation sets\n",
        "tokenized_dataset = split_dataset.map(update_label, batched=True)\n",
        "\n",
        "# Print the outputs to inspect the label mapping\n",
        "print(\"preview of dataset: \", tokenized_dataset[\"validation\"][1:10])\n",
        "print(\"labels: \", unique_labels_all)\n",
        "print(\"label mapping: \", dict(label_mapping))  # Convert defaultdict to dict for printing\n"
      ],
      "metadata": {
        "id": "A1icFgO2mRO0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f6aadc1af8114dc894be2fa4f2a9ac61",
            "eb33057d6a884e438d99833a43ffb81d",
            "14fba684a82a4c4f98f8eb83b78b554d",
            "544de4ee30574c4dbe1c6582aa4a1057",
            "39bf98fc4d5a406698f4b974e67a8581",
            "92201b6a125d4b6a9235c71c2c79b901",
            "72be5c4f32be473e863e8376ff598936",
            "2ef0d70d15f74c1ab1856298293d5b7d",
            "0e2bfdd84ac84140955c9f04eb93ac60",
            "6ceb035e7c454e4998083dae830bc4bf",
            "449d1c8bc0704dcdbc52accd36ad7919",
            "aef4efcca20044969d3b10097d614c06",
            "0992c27206a34aaaaacd69e7dfc6780a",
            "87081a361c5142ecb105beaea554ebfd",
            "def5f346118c4beebef73c0aff3f773f",
            "7c5e5246bc4c4ef8b0c361c38f2bb0bf",
            "adf00cc822f0449db4a5450c0cf49009",
            "ab3cdac2f9a644c58a5fe330c94cc477",
            "df05db760a664b29a79d0bba79e85b6c",
            "b8b3ca55104649398c32bbd2bac17db2",
            "8455c77d18da48f5beadcbbed281a6c0",
            "5354084b1871479f98a810d75b7fd8ba"
          ]
        },
        "outputId": "4b496705-c520-4c22-af85-06dcd61e0fce"
      },
      "execution_count": 488,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/392 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6aadc1af8114dc894be2fa4f2a9ac61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding label: fear\n",
            "Adding label: Neutral\n",
            "Adding label: Positive\n",
            "Adding label: Sarcastic\n",
            "Adding label: annoyance\n",
            "Adding label: restlessness\n",
            "Adding label: Serious\n",
            "Adding label: empathy\n",
            "Adding label: sadness\n",
            "Adding label: positive\n",
            "Adding label: neutral\n",
            "Adding label: disgust\n",
            "Adding label: negative\n",
            "Adding label: joy\n",
            "Adding label: awe\n",
            "Adding label: anger\n",
            "Adding label: peace\n",
            "Adding label: longing\n",
            "Adding label: disappointment\n",
            "Adding label: worry\n",
            "Adding label: reflection\n",
            "Adding label: relief\n",
            "Adding label: surprise\n",
            "Adding label: stress\n",
            "Adding label: grief\n",
            "Adding label: Negative\n",
            "Adding label: concern\n",
            "Adding label: happiness\n",
            "Adding label: connection\n",
            "Adding label: tranquility\n",
            "Adding label: tension\n",
            "Adding label: determination\n",
            "Adding label: inspiration\n",
            "Adding label: bittersweetness\n",
            "Adding label: excitement\n",
            "Adding label: sorrow\n",
            "Adding label: pleasure\n",
            "Adding label: adventure\n",
            "Adding label: amusement\n",
            "Adding label: anticipation\n",
            "Adding label: compassion\n",
            "Adding label: anxiety\n",
            "Adding label: pride\n",
            "Adding label: adrenaline\n",
            "Adding label: nostalgia\n",
            "Adding label: courage\n",
            "Adding label: loneliness\n",
            "Adding label: pain\n",
            "Adding label: love\n",
            "Adding label: bliss\n",
            "Adding label: curiosity\n",
            "Adding label: depression\n",
            "Adding label: despair\n",
            "Adding label: chill\n",
            "Adding label: parting\n",
            "Adding label: admiration\n",
            "Adding label: gratitude\n",
            "Adding label: accomplishment\n",
            "Adding label: comfort\n",
            "Adding label: contentment\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/99 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aef4efcca20044969d3b10097d614c06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding label: appreciation\n",
            "Adding label: hope\n",
            "Adding label: serenity\n",
            "Adding label: rejection\n",
            "Adding label: heat\n",
            "Adding label: elation\n",
            "preview of dataset:  {'text': [\"I can't stop thinking about the negative consequences of climate change on future generations. It's truly worrisome.\", 'Absolutely thrilled to be stuck in traffic.', \"I'm positively overjoyed to spend hours waiting for a friend who's always late.\", 'Review the latest financial report for our meeting next week.', 'Seeing a snake in the grass on a dark path gives me chills and I freeze up for a moment.', 'Just won the lottery! Best day ever!', 'Grateful for the overwhelming support during tough times.', 'Oh joy, my computer crashed again just as I was about to save my work.', 'I was utterly captivated by the enchanting performance.'], 'label': [19, 3, 3, 1, 0, 13, 9, 3, 9]}\n",
            "labels:  {'adventure', 'joy', 'chill', 'bliss', 'nostalgia', 'comfort', 'concern', 'adrenaline', 'Neutral', 'worry', 'bittersweetness', 'parting', 'despair', 'Serious', 'accomplishment', 'disgust', 'love', 'determination', 'peace', 'tension', 'longing', 'admiration', 'heat', 'surprise', 'empathy', 'stress', 'anticipation', 'depression', 'excitement', 'tranquility', 'serenity', 'annoyance', 'pride', 'rejection', 'sadness', 'Sarcastic', 'loneliness', 'happiness', 'curiosity', 'awe', 'compassion', 'connection', 'pleasure', 'positive', 'sorrow', 'hope', 'courage', 'appreciation', 'Negative', 'Positive', 'amusement', 'restlessness', 'relief', 'negative', 'fear', 'inspiration', 'grief', 'disappointment', 'pain', 'gratitude', 'elation', 'anxiety', 'neutral', 'anger', 'reflection', 'contentment'}\n",
            "label mapping:  {'fear': 0, 'Neutral': 1, 'Positive': 2, 'Sarcastic': 3, 'annoyance': 4, 'restlessness': 5, 'Serious': 6, 'empathy': 7, 'sadness': 8, 'positive': 9, 'neutral': 10, 'disgust': 11, 'negative': 12, 'joy': 13, 'awe': 14, 'anger': 15, 'peace': 16, 'longing': 17, 'disappointment': 18, 'worry': 19, 'reflection': 20, 'relief': 21, 'surprise': 22, 'stress': 23, 'grief': 24, 'Negative': 25, 'concern': 26, 'happiness': 27, 'connection': 28, 'tranquility': 29, 'tension': 30, 'determination': 31, 'inspiration': 32, 'bittersweetness': 33, 'excitement': 34, 'sorrow': 35, 'pleasure': 36, 'adventure': 37, 'amusement': 38, 'anticipation': 39, 'compassion': 40, 'anxiety': 41, 'pride': 42, 'adrenaline': 43, 'nostalgia': 44, 'courage': 45, 'loneliness': 46, 'pain': 47, 'love': 48, 'bliss': 49, 'curiosity': 50, 'depression': 51, 'despair': 52, 'chill': 53, 'parting': 54, 'admiration': 55, 'gratitude': 56, 'accomplishment': 57, 'comfort': 58, 'contentment': 59, 'appreciation': 60, 'hope': 61, 'serenity': 62, 'rejection': 63, 'heat': 64, 'elation': 65}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"preview of dataset: \", filter_dataset[\"validation\"][1:10])\n",
        "print(\"labels: \", unique_labels_all)\n",
        "print(\"label mapping: \", label_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0izWuwQXozt",
        "outputId": "3eaafef2-343a-431c-99fe-0282b04b58e9"
      },
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preview of dataset:  {'text': [\"I can't stop thinking about the negative consequences of climate change on future generations. It's truly worrisome.\", 'Absolutely thrilled to be stuck in traffic.', \"I'm positively overjoyed to spend hours waiting for a friend who's always late.\", 'Review the latest financial report for our meeting next week.', 'Seeing a snake in the grass on a dark path gives me chills and I freeze up for a moment.', 'Just won the lottery! Best day ever!', 'Grateful for the overwhelming support during tough times.', 'Oh joy, my computer crashed again just as I was about to save my work.', 'I was utterly captivated by the enchanting performance.'], 'label': [10, 36, 36, 9, 55, 2, 44, 36, 44]}\n",
            "labels:  {'adventure', 'joy', 'chill', 'bliss', 'nostalgia', 'comfort', 'concern', 'adrenaline', 'Neutral', 'worry', 'bittersweetness', 'parting', 'despair', 'Serious', 'accomplishment', 'disgust', 'love', 'determination', 'peace', 'tension', 'longing', 'admiration', 'heat', 'surprise', 'empathy', 'stress', 'anticipation', 'depression', 'excitement', 'tranquility', 'serenity', 'annoyance', 'pride', 'rejection', 'sadness', 'Sarcastic', 'loneliness', 'happiness', 'curiosity', 'awe', 'compassion', 'connection', 'pleasure', 'positive', 'sorrow', 'hope', 'courage', 'appreciation', 'Negative', 'Positive', 'amusement', 'restlessness', 'relief', 'negative', 'fear', 'inspiration', 'grief', 'disappointment', 'pain', 'gratitude', 'elation', 'anxiety', 'neutral', 'anger', 'reflection', 'contentment'}\n",
            "label mapping:  {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pre-filter header: \\n\", split_dataset['train'].take(10).to_pandas())\n",
        "print(\"post-filter header: \\n\", filter_dataset['train'].take(10).to_pandas())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiDSA_4MMrtU",
        "outputId": "b4d2ab41-0629-440f-8fbd-1c6f87fe3951"
      },
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pre-filter header: \n",
            "                                                 text         label\n",
            "0  My chest tightens with the fear of confrontati...          fear\n",
            "1  Today's menu includes salad, soup, and sandwic...       Neutral\n",
            "2  I'm thrilled to announce that my application w...      Positive\n",
            "3  Looking forward to the annual 'Employee of the...     Sarcastic\n",
            "4  Why does this always happen to me? I can't see...     annoyance\n",
            "5  My child's school performance has improved sig...      Positive\n",
            "6  The relentless drumming of rain against the wi...  restlessness\n",
            "7  The CEO's decision to lay off a significant po...       Serious\n",
            "8  Seeing the volunteers helping to clean up the ...       empathy\n",
            "9  The silence in the room is deafening, and it f...       sadness\n",
            "post-filter header: \n",
            "                                                 text  label\n",
            "0  My chest tightens with the fear of confrontati...     55\n",
            "1  Today's menu includes salad, soup, and sandwic...      9\n",
            "2  I'm thrilled to announce that my application w...     50\n",
            "3  Looking forward to the annual 'Employee of the...     36\n",
            "4  Why does this always happen to me? I can't see...     32\n",
            "5  My child's school performance has improved sig...     50\n",
            "6  The relentless drumming of rain against the wi...     52\n",
            "7  The CEO's decision to lay off a significant po...     14\n",
            "8  Seeing the volunteers helping to clean up the ...     25\n",
            "9  The silence in the room is deafening, and it f...     35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {
        "id": "zv28IXN4yRGC"
      },
      "outputs": [],
      "source": [
        "# Assuming filter_dataset is a dictionary with 'train' and 'validation' subsets\n",
        "# Apply preprocess function to each subset (train and validation)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    try:\n",
        "        # Ensure consistent tokenizer usage\n",
        "        global tokenizer\n",
        "\n",
        "        # Input extraction\n",
        "        inputs = examples[\"text\"]\n",
        "\n",
        "        # Tokenization with special token handling (if needed)\n",
        "        model_inputs = tokenizer(\n",
        "            inputs,\n",
        "            max_length=128,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            # add_special_tokens=True,  # Add if needed\n",
        "        )\n",
        "\n",
        "        # Label assignment\n",
        "        model_inputs[\"labels\"] = examples[\"label\"]\n",
        "\n",
        "        return model_inputs\n",
        "    except Exception as e:\n",
        "        print(f\"Error during preprocessing: {e}\")\n",
        "        return None  # Or handle the error appropriately\n",
        "\n",
        "# Apply the preprocess function to 'train' and 'validation' separately\n",
        "tokenized_train = filter_dataset['train'].map(preprocess_function, batched=True)\n",
        "tokenized_validation = filter_dataset['validation'].map(preprocess_function, batched=True)\n",
        "\n",
        "# If needed, you can combine the processed datasets back into a dictionary\n",
        "tokenized_dataset = {\n",
        "    'train': tokenized_train,\n",
        "    'validation': tokenized_validation\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some print statements to make sure things look ok"
      ],
      "metadata": {
        "id": "xlliANlTK0qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW03__aVpaki",
        "outputId": "1d0d5f3b-5620-44c9-bcc3-2a2b38035565"
      },
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': Dataset({\n",
            "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 392\n",
            "}), 'validation': Dataset({\n",
            "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 99\n",
            "})}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset.keys())\n",
        "print(tokenized_dataset[\"train\"].features)\n",
        "print(tokenized_dataset[\"train\"][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70T5xj4Jp3oO",
        "outputId": "63eeec73-0786-47b7-cdf1-7463c7cfc24b"
      },
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['train', 'validation'])\n",
            "{'text': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'labels': Value(dtype='int64', id=None)}\n",
            "{'text': [\"My chest tightens with the fear of confrontation, it's a dreaded emotion.\", \"Today's menu includes salad, soup, and sandwiches.\", \"I'm thrilled to announce that my application was accepted. Thanks for all the support!\", \"Looking forward to the annual 'Employee of the Month' award. It's truly a prestigious title.\", \"Why does this always happen to me? I can't seem to catch a break.\"], 'label': [55, 9, 50, 36, 32], 'input_ids': [[101, 2026, 3108, 21245, 2015, 2007, 1996, 3571, 1997, 13111, 1010, 2009, 1005, 1055, 1037, 14436, 2098, 7603, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2651, 1005, 1055, 12183, 2950, 16521, 1010, 11350, 1010, 1998, 22094, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 1005, 1049, 16082, 2000, 14970, 2008, 2026, 4646, 2001, 3970, 1012, 4283, 2005, 2035, 1996, 2490, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2559, 2830, 2000, 1996, 3296, 1005, 7904, 1997, 1996, 3204, 1005, 2400, 1012, 2009, 1005, 1055, 5621, 1037, 8919, 2516, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2339, 2515, 2023, 2467, 4148, 2000, 2033, 1029, 1045, 2064, 1005, 1056, 4025, 2000, 4608, 1037, 3338, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': [55, 9, 50, 36, 32]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the first 5 examples\n",
        "for i in range(5):\n",
        "    print(tokenized_dataset[\"train\"][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fa6xpVpq1iZ",
        "outputId": "2cfea657-0a44-4ad2-cabf-fc4e848e1a09"
      },
      "execution_count": 427,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \"My chest tightens with the fear of confrontation, it's a dreaded emotion.\", 'label': 55, 'input_ids': [101, 2026, 3108, 21245, 2015, 2007, 1996, 3571, 1997, 13111, 1010, 2009, 1005, 1055, 1037, 14436, 2098, 7603, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 55}\n",
            "{'text': \"Today's menu includes salad, soup, and sandwiches.\", 'label': 9, 'input_ids': [101, 2651, 1005, 1055, 12183, 2950, 16521, 1010, 11350, 1010, 1998, 22094, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 9}\n",
            "{'text': \"I'm thrilled to announce that my application was accepted. Thanks for all the support!\", 'label': 50, 'input_ids': [101, 1045, 1005, 1049, 16082, 2000, 14970, 2008, 2026, 4646, 2001, 3970, 1012, 4283, 2005, 2035, 1996, 2490, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 50}\n",
            "{'text': \"Looking forward to the annual 'Employee of the Month' award. It's truly a prestigious title.\", 'label': 36, 'input_ids': [101, 2559, 2830, 2000, 1996, 3296, 1005, 7904, 1997, 1996, 3204, 1005, 2400, 1012, 2009, 1005, 1055, 5621, 1037, 8919, 2516, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 36}\n",
            "{'text': \"Why does this always happen to me? I can't seem to catch a break.\", 'label': 32, 'input_ids': [101, 2339, 2515, 2023, 2467, 4148, 2000, 2033, 1029, 1045, 2064, 1005, 1056, 4025, 2000, 4608, 1037, 3338, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = tokenizer.get_vocab()\n",
        "token = vocabulary.get(2026)\n",
        "print(token)\n",
        "vocabulary_size = len(tokenizer.get_vocab())\n",
        "print(f\"Vocabulary size: {vocabulary_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O1cXejLrGZP",
        "outputId": "82405fd9-805b-4f2c-d97b-96130d35dd95"
      },
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Vocabulary size: 30522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_id in tokenized_dataset[\"train\"][1][\"input_ids\"]:\n",
        "    token = tokenizer.convert_ids_to_tokens(input_id)  # Built-in method\n",
        "    if input_id in tokenizer.all_special_ids:  # Handle special tokens\n",
        "        print(f\"Special token: {token}\")\n",
        "    else:\n",
        "        print(f\"Token: {token}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsLofngUty0r",
        "outputId": "a3b6d08a-51b9-448f-e254-b06cb4dfd82e"
      },
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special token: [CLS]\n",
            "Token: today\n",
            "Token: '\n",
            "Token: s\n",
            "Token: menu\n",
            "Token: includes\n",
            "Token: salad\n",
            "Token: ,\n",
            "Token: soup\n",
            "Token: ,\n",
            "Token: and\n",
            "Token: sandwiches\n",
            "Token: .\n",
            "Special token: [SEP]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n",
            "Special token: [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a sample of the vocabulary\n",
        "print(tokenizer.vocab_size)  # Check vocabulary size\n",
        "print(tokenizer.decode([2026]))  # Decode a specific token ID to see its mapping\n",
        "print(tokenizer.convert_ids_to_tokens([2651]))  # Convert to token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UEP3OagzVvg",
        "outputId": "cf3eff81-6770-4580-81c5-c79bf038c002"
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30522\n",
            "my\n",
            "['today']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## this is the training part.\n",
        "1. include training arguments. These arguments can be modified for fine tuning. I don't really get it though?\n",
        "2. Collate the data using torch. There's a lot of shape manipulation because the train function kept throwing an error with datatypes.\n",
        "3. Wrote a custom compute metrics function so the model will report back on metrics after running the training."
      ],
      "metadata": {
        "id": "yUsBvkpI-NE0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {
        "id": "mriw80Kfq9XY"
      },
      "outputs": [],
      "source": [
        "#fine tune model using trainer API via hugging face\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=5e-6,\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type=\"linear\",  # Or \"cosine\", \"polynomial\", etc.\n",
        "    warmup_steps=100,  # Number of warmup steps\n",
        "    logging_steps=10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a data collator. This ensures that the input_ids match the labels, which for some reason is neaded when passing all the information to tensorflow"
      ],
      "metadata": {
        "id": "nM7thR5uK9fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def custom_data_collator(data):\n",
        "    # Convert input_ids and attention_mask to tensors\n",
        "    input_ids = torch.stack([torch.tensor(x['input_ids'], dtype=torch.long) for x in data])\n",
        "    attention_mask = torch.stack([torch.tensor(x['attention_mask'], dtype=torch.long) for x in data])\n",
        "\n",
        "    # Convert labels to a tensor\n",
        "    labels = torch.tensor([x['labels'] for x in data], dtype=torch.long)\n",
        "\n",
        "    # Debugging statements\n",
        "    print(f\"input_ids shape: {input_ids.shape}\")\n",
        "    print(f\"attention_mask shape: {attention_mask.shape}\")\n",
        "    print(f\"labels shape: {labels.shape}\")\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'labels': labels,\n",
        "    }"
      ],
      "metadata": {
        "id": "stpob_Tq9rgW"
      },
      "execution_count": 440,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make a compute_metrics function, that customizes what metrics show up while running the trainer function"
      ],
      "metadata": {
        "id": "8ifVf0D1LKQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # Extract logits and labels\n",
        "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
        "\n",
        "    # Ensure logits are numpy arrays (if they're in tensor format)\n",
        "    if isinstance(logits, torch.Tensor):\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    # Ensure labels are numpy arrays (if they're in tensor format)\n",
        "    if isinstance(labels, torch.Tensor):\n",
        "        labels = labels.detach().cpu().numpy()\n",
        "\n",
        "    # Get predicted class by taking argmax along the last dimension\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove padding (ignore -100 labels)\n",
        "    valid_mask = labels != -100\n",
        "    predictions = predictions[valid_mask]\n",
        "    labels = labels[valid_mask]\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
      ],
      "metadata": {
        "id": "GycJ4rCxRKig"
      },
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {
        "id": "lYLQoh8TsREi"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    data_collator=custom_data_collator,\n",
        "    compute_metrics=compute_metrics # Pass the function here,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 443,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5Qmj9ofAsXY1",
        "outputId": "11c49092-78f7-4f59-ac3c-0b6d882a43c0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='193' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [193/196 35:02 < 00:33, 0.09 it/s, Epoch 3.92/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.149100</td>\n",
              "      <td>4.141126</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.120100</td>\n",
              "      <td>4.049891</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.012397</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.017595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.880200</td>\n",
              "      <td>3.939443</td>\n",
              "      <td>0.050505</td>\n",
              "      <td>0.011962</td>\n",
              "      <td>0.050505</td>\n",
              "      <td>0.019342</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([3, 128])\n",
            "attention_mask shape: torch.Size([3, 128])\n",
            "labels shape: torch.Size([3])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([3, 128])\n",
            "attention_mask shape: torch.Size([3, 128])\n",
            "labels shape: torch.Size([3])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([3, 128])\n",
            "attention_mask shape: torch.Size([3, 128])\n",
            "labels shape: torch.Size([3])\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='196' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [196/196 36:47, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.149100</td>\n",
              "      <td>4.141126</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.120100</td>\n",
              "      <td>4.049891</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.012397</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.017595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.880200</td>\n",
              "      <td>3.939443</td>\n",
              "      <td>0.050505</td>\n",
              "      <td>0.011962</td>\n",
              "      <td>0.050505</td>\n",
              "      <td>0.019342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.903000</td>\n",
              "      <td>3.917088</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.013085</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.021080</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([8, 128])\n",
            "attention_mask shape: torch.Size([8, 128])\n",
            "labels shape: torch.Size([8])\n",
            "input_ids shape: torch.Size([3, 128])\n",
            "attention_mask shape: torch.Size([3, 128])\n",
            "labels shape: torch.Size([3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=196, training_loss=4.0239134321407395, metrics={'train_runtime': 2220.8375, 'train_samples_per_second': 0.706, 'train_steps_per_second': 0.088, 'total_flos': 103199726837760.0, 'train_loss': 4.0239134321407395, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 443
        }
      ],
      "source": [
        "trainer.train()\n",
        "# bf19dff74bb3083b13faf628d07195823fc10890"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model output configuration: {model.config.num_labels}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9HIWZ3V0hdc",
        "outputId": "2fa325e6-c12f-401e-c4a8-0a8931576f97"
      },
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output configuration: 67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the results:\n",
        "(pasted from gemini)\n",
        "The \"good\" values for accuracy, precision, and F1 score depend on the nature of your task, the class imbalance, and what you prioritize in the performance metrics. Here's a breakdown of each metric and general guidelines:\n",
        "\n",
        "1. Accuracy:\n",
        "Definition: Accuracy is the proportion of correct predictions out of all predictions. It is calculated as:\n",
        "Accuracy\n",
        "=\n",
        "True Positives\n",
        "+\n",
        "True Negatives\n",
        "Total Samples\n",
        "Accuracy=\n",
        "Total Samples\n",
        "True Positives+True Negatives\n",
        "​\n",
        "\n",
        "Good values:\n",
        "Generally, higher accuracy is better. However, accuracy can be misleading in imbalanced datasets. For example, if 95% of your data is class A and 5% is class B, a model predicting class A all the time will have 95% accuracy but will fail to identify any instances of class B.\n",
        "A \"good\" accuracy value depends on the dataset, but over 90% is usually strong in most tasks.\n",
        "2. Precision:\n",
        "Definition: Precision measures how many of the predicted positive cases are actually positive. It is calculated as:\n",
        "Precision\n",
        "=\n",
        "True Positives\n",
        "True Positives\n",
        "+\n",
        "False Positives\n",
        "Precision=\n",
        "True Positives+False Positives\n",
        "True Positives\n",
        "​\n",
        "\n",
        "Good values:\n",
        "High precision means fewer false positives. It's important when you want to minimize the cost of false alarms (e.g., in medical diagnostics or fraud detection).\n",
        "Precision close to 1.0 is ideal (i.e., low number of false positives), but depending on the application, a precision of 0.7 or higher could be acceptable.\n",
        "3. Recall (Sensitivity):\n",
        "Definition: Recall measures how many of the actual positive cases were correctly identified. It is calculated as:\n",
        "Recall\n",
        "=\n",
        "True Positives\n",
        "True Positives\n",
        "+\n",
        "False Negatives\n",
        "Recall=\n",
        "True Positives+False Negatives\n",
        "True Positives\n",
        "​\n",
        "\n",
        "Good values:\n",
        "High recall means fewer false negatives, which is important when you don't want to miss any positive cases (e.g., in detecting diseases or rare events).\n",
        "Ideally, you want recall close to 1.0, but depending on the use case, a recall of 0.7 or higher can be acceptable.\n",
        "4. F1 Score:\n",
        "Definition: F1 score is the harmonic mean of precision and recall, providing a balance between the two. It is calculated as:\n",
        "F1\n",
        "=\n",
        "2\n",
        "×\n",
        "Precision\n",
        "×\n",
        "Recall\n",
        "Precision\n",
        "+\n",
        "Recall\n",
        "F1=2×\n",
        "Precision+Recall\n",
        "Precision×Recall\n",
        "​\n",
        "\n",
        "Good values:\n",
        "The F1 score balances the trade-off between precision and recall. A high F1 score suggests that both precision and recall are high.\n",
        "An F1 score close to 1.0 is ideal, but 0.7 or higher is typically good for many tasks, especially if the precision and recall are balanced. If precision and recall differ significantly, the F1 score will reflect that imbalance.\n",
        "What is considered a \"good\" score?\n",
        "For imbalanced data: Accuracy can be misleading in imbalanced datasets, so precision, recall, and F1 score become more important. For example, in fraud detection, you might prioritize high recall (identifying as many fraudulent cases as possible) over accuracy.\n",
        "\n",
        "General guidelines:\n",
        "\n",
        "Precision and recall should both be as high as possible, but they may need to be balanced based on the application (e.g., medical diagnosis vs. general classification).\n",
        "F1 score is often considered the best metric when you need to balance precision and recall, especially if you're unsure which one to prioritize.\n",
        "Example in practice:\n",
        "High precision, lower recall: This is acceptable when false positives are more costly than false negatives (e.g., detecting rare diseases where you don't want to misclassify a healthy person as sick).\n",
        "High recall, lower precision: This is better when missing positives is more costly than false alarms (e.g., detecting a rare condition and avoiding missing any positive cases).\n",
        "Benchmarks:\n",
        "Good scores in balanced datasets:\n",
        "\n",
        "Accuracy: > 85%\n",
        "Precision: > 0.75\n",
        "Recall: > 0.75\n",
        "F1 Score: > 0.75\n",
        "Good scores in imbalanced datasets (depending on class imbalance):\n",
        "\n",
        "Precision and Recall values might vary based on how much you care about false positives or false negatives. Aim for high F1 score in these cases."
      ],
      "metadata": {
        "id": "DEXT0SGl8ZnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#export the model and convert to ONNX"
      ],
      "metadata": {
        "id": "twKKttmv-0ZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {
        "id": "aWqvLaHMyhIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318468f9-ae49-443e-eb12-bc29b422d461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model files: \n",
            "\n",
            "tokenizer files: \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine_tuned_model/tokenizer_config.json',\n",
              " './fine_tuned_model/special_tokens_map.json',\n",
              " './fine_tuned_model/vocab.txt',\n",
              " './fine_tuned_model/added_tokens.json',\n",
              " './fine_tuned_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 445
        }
      ],
      "source": [
        "#Export fine tune model\n",
        "print(\"model files: \\n\")\n",
        "model.save_pretrained(\"./fine_tuned_model\", safe_serialization=False)\n",
        "print(\"tokenizer files: \\n\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of the files:\n",
        "- added_tokens.json: This file contains additional tokens added to the model's vocabulary.\n",
        "- config.json: Contains model-specific configuration settings.\n",
        "- generation_config.json: Model-specific settings related to generation tasks (not directly relevant for tokenization).\n",
        "- special_tokens_map.json: Maps special tokens such as [CLS], [SEP], etc.\n",
        "- spiece.model: The SentencePiece model file containing the vocabulary and subword segmentation rules.\n",
        "- tokenizer_config.json: Configuration for the tokenizer itself."
      ],
      "metadata": {
        "id": "CsXiPVKXcrv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the code to convert the exported model to ONNX."
      ],
      "metadata": {
        "id": "0yx6BC6Lq-qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optimum[onnxruntime]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO5kVLkQ6IHL",
        "outputId": "f7a56a16-0d47-474f-a0a9-d39e7a46003d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optimum[onnxruntime] in /usr/local/lib/python3.10/dist-packages (1.23.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (1.13.1)\n",
            "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (4.46.2)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (2.5.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (1.26.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (0.26.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (3.1.0)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (1.17.0)\n",
            "Requirement already satisfied: onnxruntime>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (1.20.1)\n",
            "Collecting evaluate (from optimum[onnxruntime])\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.1 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]) (4.25.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime]) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime]) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime]) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime]) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->optimum[onnxruntime]) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime]) (3.11.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime]) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime]) (4.12.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]) (24.3.25)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum[onnxruntime]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum[onnxruntime]) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum[onnxruntime]) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum[onnxruntime]) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum[onnxruntime]) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum[onnxruntime]) (0.20.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum[onnxruntime]) (10.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime]) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime]) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime]) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime]) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime]) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->optimum[onnxruntime]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->optimum[onnxruntime]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->optimum[onnxruntime]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->optimum[onnxruntime]) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->optimum[onnxruntime]) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum[onnxruntime]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum[onnxruntime]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum[onnxruntime]) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum[onnxruntime]) (1.16.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as rt\n",
        "import onnx"
      ],
      "metadata": {
        "id": "3-74FgjHsGoZ"
      },
      "execution_count": 446,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load your trained model and tokenizer\n",
        "model_path = \"./fine_tuned_model\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Define dummy input for the model, include special tokens and attention mask\n",
        "text = \"This is a test sentence.\"  # Example text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# Export to ONNX\n",
        "onnx_path = \"./fine_tuned_model/onnx_model/model.onnx\"\n",
        "torch.onnx.export(\n",
        "    model,                       # The trained model\n",
        "    inputs.data,                  # Provide the tokenized input as a dictionary\n",
        "    onnx_path,                   # Path where ONNX model will be saved\n",
        "    input_names=[\"input_ids\", \"attention_mask\"],   # Name of input layers\n",
        "    output_names=[\"logits\"],     # Name of output layers\n",
        "    dynamic_axes={\"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
        "                  \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
        "                  \"logits\": {0: \"batch_size\"}},  # Dynamic axes\n",
        "    opset_version=14             # Changed opset version to 14\n",
        ")\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(\"./fine_tuned_model/onnx_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvGgTFcrsMNe",
        "outputId": "a7e250df-4a97-4722-da0d-a262190f2e91"
      },
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ./fine_tuned_model were not used when initializing BertForSequenceClassification: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.final_layer_norm.weight', 'shared.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./fine_tuned_model and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine_tuned_model/onnx_model/tokenizer_config.json',\n",
              " './fine_tuned_model/onnx_model/special_tokens_map.json',\n",
              " './fine_tuned_model/onnx_model/vocab.txt',\n",
              " './fine_tuned_model/onnx_model/added_tokens.json',\n",
              " './fine_tuned_model/onnx_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 452
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "\n",
        "# Quantize ONNX model\n",
        "onnx_model_path = \"./fine_tuned_model/onnx_model/model.onnx\"\n",
        "quantized_model_path = \"./fine_tuned_model/onnx_model/model-quantized.onnx\"\n",
        "\n",
        "quantize_dynamic(\n",
        "    model_input=onnx_model_path,\n",
        "    model_output=quantized_model_path,\n",
        "    weight_type=QuantType.QUInt8  # Use INT8 quantization\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LyKwBQPsTib",
        "outputId": "a97ed21f-e9ae-4c66-ffd5-66b39f655c40"
      },
      "execution_count": 448,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_model\")\n",
        "\n",
        "# Save as tokenizer.json\n",
        "tokenizer.save_pretrained(\"./fine_tuned_model\", legacy_format=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG_CCvI37xJw",
        "outputId": "15035722-f9d5-4a15-85ec-b62ac5bde487"
      },
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine_tuned_model/tokenizer_config.json',\n",
              " './fine_tuned_model/special_tokens_map.json',\n",
              " './fine_tuned_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 449
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test the model"
      ],
      "metadata": {
        "id": "vWgo40X2G2UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./fine_tuned_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_model\")\n",
        "\n",
        "# Example manual input\n",
        "input_text = \"I am very sad.\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# Get model predictions\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "# Get predicted class by taking argmax of logits\n",
        "predicted_class = logits.argmax(dim=-1).item()  # Convert to a Python scalar\n",
        "\n",
        "# Get the predicted label\n",
        "# Reversing the label_mapping to create a mapping from integers to labels\n",
        "inverted_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "print(\"predicted class: \", predicted_class)\n",
        "predicted_label = inverted_label_mapping.get(predicted_class, \"Unknown\")\n",
        "print(f\"Predicted label: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxghJ_R4bPQf",
        "outputId": "f0ae4fd0-485b-4200-f4da-a551ad1e3d0b"
      },
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ./fine_tuned_model were not used when initializing BertForSequenceClassification: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.final_layer_norm.weight', 'shared.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./fine_tuned_model and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted class:  18\n",
            "Predicted label: disappointment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_mapping)"
      ],
      "metadata": {
        "id": "Z76Pa_77n5dD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b93c3b4-52b6-4e13-c089-74253f8ea11c"
      },
      "execution_count": 490,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<function <lambda> at 0x7c3d8913f910>, {'fear': 0, 'Neutral': 1, 'Positive': 2, 'Sarcastic': 3, 'annoyance': 4, 'restlessness': 5, 'Serious': 6, 'empathy': 7, 'sadness': 8, 'positive': 9, 'neutral': 10, 'disgust': 11, 'negative': 12, 'joy': 13, 'awe': 14, 'anger': 15, 'peace': 16, 'longing': 17, 'disappointment': 18, 'worry': 19, 'reflection': 20, 'relief': 21, 'surprise': 22, 'stress': 23, 'grief': 24, 'Negative': 25, 'concern': 26, 'happiness': 27, 'connection': 28, 'tranquility': 29, 'tension': 30, 'determination': 31, 'inspiration': 32, 'bittersweetness': 33, 'excitement': 34, 'sorrow': 35, 'pleasure': 36, 'adventure': 37, 'amusement': 38, 'anticipation': 39, 'compassion': 40, 'anxiety': 41, 'pride': 42, 'adrenaline': 43, 'nostalgia': 44, 'courage': 45, 'loneliness': 46, 'pain': 47, 'love': 48, 'bliss': 49, 'curiosity': 50, 'depression': 51, 'despair': 52, 'chill': 53, 'parting': 54, 'admiration': 55, 'gratitude': 56, 'accomplishment': 57, 'comfort': 58, 'contentment': 59, 'appreciation': 60, 'hope': 61, 'serenity': 62, 'rejection': 63, 'heat': 64, 'elation': 65})\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f6aadc1af8114dc894be2fa4f2a9ac61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb33057d6a884e438d99833a43ffb81d",
              "IPY_MODEL_14fba684a82a4c4f98f8eb83b78b554d",
              "IPY_MODEL_544de4ee30574c4dbe1c6582aa4a1057"
            ],
            "layout": "IPY_MODEL_39bf98fc4d5a406698f4b974e67a8581"
          }
        },
        "eb33057d6a884e438d99833a43ffb81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92201b6a125d4b6a9235c71c2c79b901",
            "placeholder": "​",
            "style": "IPY_MODEL_72be5c4f32be473e863e8376ff598936",
            "value": "Map: 100%"
          }
        },
        "14fba684a82a4c4f98f8eb83b78b554d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ef0d70d15f74c1ab1856298293d5b7d",
            "max": 392,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e2bfdd84ac84140955c9f04eb93ac60",
            "value": 392
          }
        },
        "544de4ee30574c4dbe1c6582aa4a1057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ceb035e7c454e4998083dae830bc4bf",
            "placeholder": "​",
            "style": "IPY_MODEL_449d1c8bc0704dcdbc52accd36ad7919",
            "value": " 392/392 [00:00&lt;00:00, 3568.81 examples/s]"
          }
        },
        "39bf98fc4d5a406698f4b974e67a8581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92201b6a125d4b6a9235c71c2c79b901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72be5c4f32be473e863e8376ff598936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ef0d70d15f74c1ab1856298293d5b7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2bfdd84ac84140955c9f04eb93ac60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ceb035e7c454e4998083dae830bc4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449d1c8bc0704dcdbc52accd36ad7919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aef4efcca20044969d3b10097d614c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0992c27206a34aaaaacd69e7dfc6780a",
              "IPY_MODEL_87081a361c5142ecb105beaea554ebfd",
              "IPY_MODEL_def5f346118c4beebef73c0aff3f773f"
            ],
            "layout": "IPY_MODEL_7c5e5246bc4c4ef8b0c361c38f2bb0bf"
          }
        },
        "0992c27206a34aaaaacd69e7dfc6780a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adf00cc822f0449db4a5450c0cf49009",
            "placeholder": "​",
            "style": "IPY_MODEL_ab3cdac2f9a644c58a5fe330c94cc477",
            "value": "Map: 100%"
          }
        },
        "87081a361c5142ecb105beaea554ebfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df05db760a664b29a79d0bba79e85b6c",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8b3ca55104649398c32bbd2bac17db2",
            "value": 99
          }
        },
        "def5f346118c4beebef73c0aff3f773f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8455c77d18da48f5beadcbbed281a6c0",
            "placeholder": "​",
            "style": "IPY_MODEL_5354084b1871479f98a810d75b7fd8ba",
            "value": " 99/99 [00:00&lt;00:00, 1016.29 examples/s]"
          }
        },
        "7c5e5246bc4c4ef8b0c361c38f2bb0bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf00cc822f0449db4a5450c0cf49009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3cdac2f9a644c58a5fe330c94cc477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df05db760a664b29a79d0bba79e85b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b3ca55104649398c32bbd2bac17db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8455c77d18da48f5beadcbbed281a6c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5354084b1871479f98a810d75b7fd8ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}